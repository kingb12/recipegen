{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a62d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pprint import pprint\n",
    "import datasets\n",
    "from typing import List, Dict\n",
    "import random\n",
    "from transformers import BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2021652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset recipe_nlg_lite (/Users/bking/.cache/huggingface/datasets/recipe_nlg_lite/1.0.0/1.0.0/2fd5f76dc1ed88ff2d6485b11497d6ae9516f4ebb2a6cb528dfaf0520bd8e51a)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"m3hrdadfi/recipe_nlg_lite\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60dddbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['uid', 'name', 'description', 'link', 'ner', 'ingredients', 'steps'],\n",
      "    num_rows: 6118\n",
      "})\n",
      "(6118, 7)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "pprint(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bdad1",
   "metadata": {},
   "source": [
    "### What keys are available on an example?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416bc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'we all know how satisfying it is to make great pork '\n",
      "                'tenderloin, ribs, or a roast but the end of the meal creates '\n",
      "                'a new quandary what do you do with the leftover pork contrary '\n",
      "                \"to what you might think, it's not that difficult . how to \"\n",
      "                'repurpose your meal is where real cooking creativity comes '\n",
      "                'into play, so let us present to you our favorite pork chop '\n",
      "                \"soup recipe . with this recipe, you'll discover how the \"\n",
      "                'natural bold flavor of pork gives this hearty soup a lift '\n",
      "                \"that a vegetable soup or chicken noodle soup just can't get . \"\n",
      "                \"it's a dinner recipe to warm you up on a cold winter night or \"\n",
      "                'a midday restorative for a long work week . throw all the '\n",
      "                'ingredients in a large pot and let it simmer on the stove for '\n",
      "                'a couple hours, or turn it into a slow cooker recipe and let '\n",
      "                'it percolate for an afternoon . this foolproof recipe '\n",
      "                'transforms your favorite comfort food into an easy meal to '\n",
      "                'warm you up again and again . the health benefits of pork '\n",
      "                \"pork is a great option if you're on a low carb diet or trying \"\n",
      "                'to up your protein intake . the protein percentage of leaner '\n",
      "                'cuts of pork can be as high as 89 percent pork also provides '\n",
      "                'valuable vitamins and minerals that make pork recipes worthy '\n",
      "                'endeavors . pork has high levels of thiamin and niacin, which '\n",
      "                'other types of meat like beef and lamb lack . they are both b '\n",
      "                'vitamins that aid in several body functions such as '\n",
      "                'metabolism and cell function . pork also delivers a healthy '\n",
      "                'amount of zinc, which aids in brain and immune system '\n",
      "                'function . that makes digging into this pork chop noodle soup '\n",
      "                'all the more alluring . recipe variations this pork soup '\n",
      "                \"recipe can be adapted to many diets . if you're following a \"\n",
      "                'low carb or ketogenic diet, you can modify the recipe to suit '\n",
      "                'you by leaving out the noodles . if you like, you can add a '\n",
      "                'little crunch by topping it with french fried onions . for '\n",
      "                'cheese lovers, a sprinkle of parmesan cheese can give the '\n",
      "                \"soup more body and extra umami flavors . if you're not a \"\n",
      "                'noodle lover, this soup recipe works equally well as a potato '\n",
      "                'soup with diced potatoes . if you want to make a southwestern '\n",
      "                'or mexican version, add a can of diced tomatoes and bell '\n",
      "                'peppers for a little extra depth . if you have a penchant for '\n",
      "                'spicy soups, add a little chili powder or red pepper flakes . '\n",
      "                \"it's up to you this recipe is great for using up leftover \"\n",
      "                'pork chops, but you can make this soup using fresh chops '\n",
      "                \"however you decide to do it, you won't be disappointed.\",\n",
      " 'ingredients': '3.0 bone in pork chops, salt, pepper, 2.0 tablespoon '\n",
      "                'vegetable oil, 2.0 cup chicken broth, 4.0 cup vegetable '\n",
      "                'broth, 1.0 red onion, 4.0 carrots, 2.0 clove garlic, 1.0 '\n",
      "                'teaspoon dried thyme, 0.5 teaspoon dried basil, 1.0 cup '\n",
      "                'rotini pasta, 2.0 stalk celery',\n",
      " 'link': 'https://www.yummly.com/private/recipe/Pork-Chop-Noodle-Soup-2249011?layout=prep-steps',\n",
      " 'name': 'pork chop noodle soup',\n",
      " 'ner': 'bone in pork chops, salt, pepper, vegetable oil, chicken broth, '\n",
      "        'vegetable broth, red onion, carrots, garlic, dried thyme, dried '\n",
      "        'basil, rotini pasta, celery',\n",
      " 'steps': 'season pork chops with salt and pepper . heat oil in a dutch oven '\n",
      "          'over medium high heat . add chops and cook for about 4 minutes, '\n",
      "          'until golden brown . flip and cook 4 minutes more, until golden '\n",
      "          'brown . transfer chops to a plate and set aside . pour half of '\n",
      "          'chicken broth into pot, scraping all browned bits from bottom . add '\n",
      "          'remaining chicken broth, vegetable broth, onion, carrots, celery '\n",
      "          'and garlic . mix well and bring to a simmer . add 1 quart water, '\n",
      "          'thyme, basil, 2 teaspoons salt and 1 teaspoon pepper . mix well and '\n",
      "          'bring to a simmer . add chops back to pot and return to simmer . '\n",
      "          'reduce heat and simmer for 90 minutes, stirring occasionally, being '\n",
      "          'careful not to break up chops . transfer chops to plate, trying not '\n",
      "          'to break them up . set aside to cool . raise the heat and bring the '\n",
      "          'soup to a boil . add pasta and cook for about 12 minutes, until '\n",
      "          'tender . when the chops are cool, pull them apart, discarding all '\n",
      "          'the bones and fat . add the meat back to soup and stir well . taste '\n",
      "          'for salt and pepper, and add if needed, before serving.',\n",
      " 'uid': 'dab8b7d0-e0f6-4bb0-aed9-346e80dace1f'}\n"
     ]
    }
   ],
   "source": [
    "# What keys are available?\n",
    "dataset[0].keys()\n",
    "from pprint import pprint\n",
    "pprint(dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f9e09",
   "metadata": {},
   "source": [
    "### Qualities of an Example\n",
    "\n",
    "#### `description`\n",
    "\n",
    "The description field is a **single free-text string** describing the dish, likely the header content needed for a recipe to appear on search indexes. It contextualizes the recipe to some degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "712278ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = dataset[0]\n",
    "assert type(example['description']) == str, f\"It's actually {type(example['description'])}\"\n",
    "\n",
    "# note the long length\n",
    "assert len(example['description']) == 2426, f\"It's actually {len(example['description'])}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377ffa0",
   "metadata": {},
   "source": [
    "#### `ingredients`\n",
    "\n",
    "The `ingredients` field is a **single free-text string** listing the ingredients in the recipe. \n",
    "\n",
    "##### Question: what pre-processing occurred here?\n",
    "- units are inconsistent\n",
    "  - an ingredient **does not** need to have a unit (e.g. 'salt' in list).\n",
    "- has ingredients comma separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f97599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 bone in pork chops, salt, pepper, 2.0 tablespoon vegetable oil, 2.0 cup chicken broth, 4.0 cup vegetable broth, 1.0 red onion, 4.0 carrots, 2.0 clove garlic, 1.0 teaspoon dried thyme, 0.5 teaspoon dried basil, 1.0 cup rotini pasta, 2.0 stalk celery\n"
     ]
    }
   ],
   "source": [
    "print(example['ingredients'])\n",
    "assert type(example['ingredients']) == str, f\"It's actually {type(example['ingredients'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fa050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 large eggs, 3 large egg whites, 2/3 cup sugar, 1 tsp pure vanilla extract, pinch fine sea salt, 2 cups 200 grams almond flour or almond meal, 1 cup mixed berries, powdered sugar\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1]['ingredients'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3af424",
   "metadata": {},
   "source": [
    "Note in this case, units have no decimal points. Still comma-separated. How could we detect when a comma was/wasn't replaced in a single-ingredient item?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6e2c6",
   "metadata": {},
   "source": [
    "#### `name`\n",
    "\n",
    "`name` is the (string) name of the dish.\n",
    "\n",
    "#### `ner`\n",
    "\n",
    "The `ner` is a **single free-text string** listing the recognized named entities in the recipe. \n",
    "\n",
    "##### Question: what pre-processing occurred here?\n",
    "- is this only equivalent to the ingredients list? \n",
    "  - **Yes**: for each item in `ner`, there is exactly one ingredient in `ingredients`.\n",
    "- are named entities in each recipe always a substring of ingredients? \n",
    "  - **Yes**: the NER parser does not do insertions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5913a289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bone in pork chops, salt, pepper, vegetable oil, chicken broth, vegetable broth, red onion, carrots, garlic, dried thyme, dried basil, rotini pasta, celery\n"
     ]
    }
   ],
   "source": [
    "print(example['ner'])\n",
    "\n",
    "# is this only equivalent to the ingredients list?\n",
    "for e in dataset:\n",
    "    ing_list = e['ingredients'].split(',')\n",
    "    ner_list = e['ner'].split(',')\n",
    "    assert len(ing_list) == len(ner_list), f\"Not the same. ingredients: {e['ingredients']}, ner: {e['ner']}\"\n",
    "    for ne in ner_list:\n",
    "        # are named entities in each recipe always a substring of ingredients?\n",
    "        assert ne in e['ingredients']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d2652",
   "metadata": {},
   "source": [
    "#### `steps`\n",
    "\n",
    "The `steps` is a **single free-text string** listing the steps for producting the recipe. Note: it is seemingly separated with `.` instead of `,`, as steps in a recipe might include commas for complex steps, or context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3c14fa",
   "metadata": {},
   "source": [
    "## Simple pre-processing\n",
    "\n",
    "Goal: un-pack each `ner` and `ingredients` into sentences, broken up by `,`\n",
    "\n",
    "- use [`datasets.map`](https://huggingface.co/docs/datasets/process.html#map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb8e3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method map in module datasets.arrow_dataset:\n",
      "\n",
      "map(function: Union[Callable, NoneType] = None, with_indices: bool = False, input_columns: Union[str, List[str], NoneType] = None, batched: bool = False, batch_size: Union[int, NoneType] = 1000, drop_last_batch: bool = False, remove_columns: Union[str, List[str], NoneType] = None, keep_in_memory: bool = False, load_from_cache_file: bool = None, cache_file_name: Union[str, NoneType] = None, writer_batch_size: Union[int, NoneType] = 1000, features: Union[datasets.features.Features, NoneType] = None, disable_nullable: bool = False, fn_kwargs: Union[dict, NoneType] = None, num_proc: Union[int, NoneType] = None, suffix_template: str = '_{rank:05d}_of_{num_proc:05d}', new_fingerprint: Union[str, NoneType] = None, desc: Union[str, NoneType] = None) -> 'Dataset' method of datasets.arrow_dataset.Dataset instance\n",
      "    Apply a function to all the elements in the table (individually or in batches)\n",
      "    and update the table (if function does update examples).\n",
      "    \n",
      "    Args:\n",
      "        function (:obj:`Callable`): Function with one of the following signatures:\n",
      "    \n",
      "            - `function(example: Union[Dict, Any]) -> Union[Dict, Any]` if `batched=False` and `with_indices=False`\n",
      "            - `function(example: Union[Dict, Any], indices: int) -> Union[Dict, Any]` if `batched=False` and `with_indices=True`\n",
      "            - `function(batch: Union[Dict[List], List[Any]]) -> Union[Dict, Any]` if `batched=True` and `with_indices=False`\n",
      "            - `function(batch: Union[Dict[List], List[Any]], indices: List[int]) -> Union[Dict, Any]` if `batched=True` and `with_indices=True`\n",
      "    \n",
      "            If no function is provided, default to identity function: ``lambda x: x``.\n",
      "        with_indices (:obj:`bool`, default `False`): Provide example indices to `function`. Note that in this case the\n",
      "            signature of `function` should be `def function(example, idx): ...`.\n",
      "        input_columns (`Optional[Union[str, List[str]]]`, default `None`): The columns to be passed into `function`\n",
      "            as positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.\n",
      "        batched (:obj:`bool`, default `False`): Provide batch of examples to `function`.\n",
      "        batch_size (`Optional[int]`, default `1000`): Number of examples per batch provided to `function` if `batched=True`\n",
      "            `batch_size <= 0` or `batch_size == None`: Provide the full dataset as a single batch to `function`.\n",
      "        drop_last_batch (:obj:`bool`, default `False`): Whether a last batch smaller than the batch_size should be\n",
      "            dropped instead of being processed by the function.\n",
      "        remove_columns (`Optional[Union[str, List[str]]]`, default `None`): Remove a selection of columns while doing the mapping.\n",
      "            Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding\n",
      "            columns with names in `remove_columns`, these columns will be kept.\n",
      "        keep_in_memory (:obj:`bool`, default `False`): Keep the dataset in memory instead of writing it to a cache file.\n",
      "        load_from_cache_file (:obj:`bool`, default `True` if caching is enabled): If a cache file storing the current computation from `function`\n",
      "            can be identified, use it instead of recomputing.\n",
      "        cache_file_name (`Optional[str]`, default `None`): Provide the name of a path for the cache file. It is used to store the\n",
      "            results of the computation instead of the automatically generated cache file name.\n",
      "        writer_batch_size (:obj:`int`, default `1000`): Number of rows per write operation for the cache file writer.\n",
      "            This value is a good trade-off between memory usage during the processing, and processing speed.\n",
      "            Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `.map()`.\n",
      "        features (`Optional[datasets.Features]`, default `None`): Use a specific Features to store the cache file\n",
      "            instead of the automatically generated one.\n",
      "        disable_nullable (:obj:`bool`, default `True`): Disallow null values in the table.\n",
      "        fn_kwargs (`Optional[Dict]`, default `None`): Keyword arguments to be passed to `function`.\n",
      "        num_proc (`Optional[int]`, default `None`): Max number of processes when generating cache. Already cached shards are loaded sequentially\n",
      "        suffix_template (:obj:`str`):\n",
      "            If cache_file_name is specified, then this suffix\n",
      "            will be added at the end of the base name of each: defaults to \"_{rank:05d}_of_{num_proc:05d}\". For example, if cache_file_name is \"processed.arrow\", then for\n",
      "            rank=1 and num_proc=4, the resulting file would be \"processed_00001_of_00004.arrow\" for the default suffix.\n",
      "        new_fingerprint (`Optional[str]`, default `None`): the new fingerprint of the dataset after transform.\n",
      "            If `None`, the new fingerprint is computed using a hash of the previous fingerprint, and the transform arguments.\n",
      "        desc (`Optional[str]`, defaults to `None`): Meaningful description to be displayed alongside with the progress bar while mapping examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dataset.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c086af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/bking/.cache/huggingface/datasets/recipe_nlg_lite/1.0.0/1.0.0/2fd5f76dc1ed88ff2d6485b11497d6ae9516f4ebb2a6cb528dfaf0520bd8e51a/cache-cb14d71c09ec9bb6.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'uid': 'dab8b7d0-e0f6-4bb0-aed9-346e80dace1f',\n",
       " 'name': 'pork chop noodle soup',\n",
       " 'description': \"we all know how satisfying it is to make great pork tenderloin, ribs, or a roast but the end of the meal creates a new quandary what do you do with the leftover pork contrary to what you might think, it's not that difficult . how to repurpose your meal is where real cooking creativity comes into play, so let us present to you our favorite pork chop soup recipe . with this recipe, you'll discover how the natural bold flavor of pork gives this hearty soup a lift that a vegetable soup or chicken noodle soup just can't get . it's a dinner recipe to warm you up on a cold winter night or a midday restorative for a long work week . throw all the ingredients in a large pot and let it simmer on the stove for a couple hours, or turn it into a slow cooker recipe and let it percolate for an afternoon . this foolproof recipe transforms your favorite comfort food into an easy meal to warm you up again and again . the health benefits of pork pork is a great option if you're on a low carb diet or trying to up your protein intake . the protein percentage of leaner cuts of pork can be as high as 89 percent pork also provides valuable vitamins and minerals that make pork recipes worthy endeavors . pork has high levels of thiamin and niacin, which other types of meat like beef and lamb lack . they are both b vitamins that aid in several body functions such as metabolism and cell function . pork also delivers a healthy amount of zinc, which aids in brain and immune system function . that makes digging into this pork chop noodle soup all the more alluring . recipe variations this pork soup recipe can be adapted to many diets . if you're following a low carb or ketogenic diet, you can modify the recipe to suit you by leaving out the noodles . if you like, you can add a little crunch by topping it with french fried onions . for cheese lovers, a sprinkle of parmesan cheese can give the soup more body and extra umami flavors . if you're not a noodle lover, this soup recipe works equally well as a potato soup with diced potatoes . if you want to make a southwestern or mexican version, add a can of diced tomatoes and bell peppers for a little extra depth . if you have a penchant for spicy soups, add a little chili powder or red pepper flakes . it's up to you this recipe is great for using up leftover pork chops, but you can make this soup using fresh chops however you decide to do it, you won't be disappointed.\",\n",
       " 'link': 'https://www.yummly.com/private/recipe/Pork-Chop-Noodle-Soup-2249011?layout=prep-steps',\n",
       " 'ner': ['bone in pork chops',\n",
       "  ' salt',\n",
       "  ' pepper',\n",
       "  ' vegetable oil',\n",
       "  ' chicken broth',\n",
       "  ' vegetable broth',\n",
       "  ' red onion',\n",
       "  ' carrots',\n",
       "  ' garlic',\n",
       "  ' dried thyme',\n",
       "  ' dried basil',\n",
       "  ' rotini pasta',\n",
       "  ' celery'],\n",
       " 'ingredients': ['3.0 bone in pork chops',\n",
       "  ' salt',\n",
       "  ' pepper',\n",
       "  ' 2.0 tablespoon vegetable oil',\n",
       "  ' 2.0 cup chicken broth',\n",
       "  ' 4.0 cup vegetable broth',\n",
       "  ' 1.0 red onion',\n",
       "  ' 4.0 carrots',\n",
       "  ' 2.0 clove garlic',\n",
       "  ' 1.0 teaspoon dried thyme',\n",
       "  ' 0.5 teaspoon dried basil',\n",
       "  ' 1.0 cup rotini pasta',\n",
       "  ' 2.0 stalk celery'],\n",
       " 'steps': 'season pork chops with salt and pepper . heat oil in a dutch oven over medium high heat . add chops and cook for about 4 minutes, until golden brown . flip and cook 4 minutes more, until golden brown . transfer chops to a plate and set aside . pour half of chicken broth into pot, scraping all browned bits from bottom . add remaining chicken broth, vegetable broth, onion, carrots, celery and garlic . mix well and bring to a simmer . add 1 quart water, thyme, basil, 2 teaspoons salt and 1 teaspoon pepper . mix well and bring to a simmer . add chops back to pot and return to simmer . reduce heat and simmer for 90 minutes, stirring occasionally, being careful not to break up chops . transfer chops to plate, trying not to break them up . set aside to cool . raise the heat and bring the soup to a boil . add pasta and cook for about 12 minutes, until tender . when the chops are cool, pull them apart, discarding all the bones and fat . add the meat back to soup and stir well . taste for salt and pepper, and add if needed, before serving.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_commas(e: Dict, keys: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    'a, b, c' -> ['a', 'b', 'c'] on all atrributes in e under argument keys\n",
    "    \"\"\"\n",
    "    for k in keys:\n",
    "        e[k] = e[k].split(',')\n",
    "    return e\n",
    "\n",
    "split_data = dataset.map(lambda e: split_commas(e, ['ner', 'ingredients']))\n",
    "split_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f05f1",
   "metadata": {},
   "source": [
    "## A more realistic example: tokenization!\n",
    "\n",
    "\n",
    "Here we'll tokenize the data so that it can support training of a transformer w/ `torch`. Specifically, we should (nearly) trivially be able to reproduce the `ner` as a target from the `ingredients`.\n",
    "\n",
    "Here, we'll consider all `ingredients` in all recipes to be independent of each other and the containing recipe. As an exercise we'll include a shuffle step. We'll tokenize using BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f9e2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ingredients_and_ner_pairs(example: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Given an example from \n",
    "    \"\"\"\n",
    "    output = {'data': []}\n",
    "    ingredients = example['ingredients'].split(',')\n",
    "    ners = example['ner'].split(',')\n",
    "    for i, ing in enumerate(ingredients):\n",
    "        output['data'].append({'ingredient': ing, 'ner': ners[i]})\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34fb2dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/bking/.cache/huggingface/datasets/recipe_nlg_lite/1.0.0/1.0.0/2fd5f76dc1ed88ff2d6485b11497d6ae9516f4ebb2a6cb528dfaf0520bd8e51a/cache-40ab3167e1859b88.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': [{'ingredient': '3.0 bone in pork chops',\n",
       "   'ner': 'bone in pork chops'},\n",
       "  {'ingredient': ' salt', 'ner': ' salt'},\n",
       "  {'ingredient': ' pepper', 'ner': ' pepper'},\n",
       "  {'ingredient': ' 2.0 tablespoon vegetable oil', 'ner': ' vegetable oil'},\n",
       "  {'ingredient': ' 2.0 cup chicken broth', 'ner': ' chicken broth'},\n",
       "  {'ingredient': ' 4.0 cup vegetable broth', 'ner': ' vegetable broth'},\n",
       "  {'ingredient': ' 1.0 red onion', 'ner': ' red onion'},\n",
       "  {'ingredient': ' 4.0 carrots', 'ner': ' carrots'},\n",
       "  {'ingredient': ' 2.0 clove garlic', 'ner': ' garlic'},\n",
       "  {'ingredient': ' 1.0 teaspoon dried thyme', 'ner': ' dried thyme'},\n",
       "  {'ingredient': ' 0.5 teaspoon dried basil', 'ner': ' dried basil'},\n",
       "  {'ingredient': ' 1.0 cup rotini pasta', 'ner': ' rotini pasta'},\n",
       "  {'ingredient': ' 2.0 stalk celery', 'ner': ' celery'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_data = dataset.map(extract_ingredients_and_ner_pairs, remove_columns=dataset.column_names)\n",
    "extracted_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c6688",
   "metadata": {},
   "source": [
    "#### Problem encountered\n",
    "\n",
    "We were able to get the data we want, but unfortunately it is still packed in to parent examples. Each example from the recipe set has a `data` attribute with a **`list`** of `(ingredient, ner)` pairs. To my knowledge, datasets has no `map` or map-like capability that allows expansion of one example into many. To get around this, we'll create a new dataset based off a single example, then use the `add_item` method to add them all. We won't be able to use the parallel processing methods in `datasets`, though technically we weren't using it already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaeb841c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['ingredient', 'ner'],\n",
       "    num_rows: 62731\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'ingredient': [], 'ner': []}\n",
    "for e in extracted_data:\n",
    "    for pair in e['data']:\n",
    "        data['ingredient'].append(pair['ingredient'])\n",
    "        data['ner'].append(pair['ner'])\n",
    "        \n",
    "untokenized_ing_ner_pairs = datasets.Dataset.from_dict(data)\n",
    "untokenized_ing_ner_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5bd7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingredient': ' 1/4 cup red onion', 'ner': ' red onion'}\n",
      "{'ingredient': \" about 8 cups confectioners' sugar\", 'ner': \" confectioners' sugar\"}\n",
      "{'ingredient': ' 2 tsp vanilla', 'ner': ' vanilla'}\n",
      "{'ingredient': ' 3.0 teaspoon soy sauce', 'ner': ' soy sauce'}\n",
      "{'ingredient': ' olive oil spray', 'ner': ' olive oil spray'}\n",
      "{'ingredient': ' 2.0 bananen', 'ner': ' bananen'}\n",
      "{'ingredient': ' 1.0 bok choy', 'ner': ' bok choy'}\n",
      "{'ingredient': ' 2 high fiber low carb whole wheat wraps', 'ner': ' high fiber low carb whole wheat wraps'}\n"
     ]
    }
   ],
   "source": [
    "# inspect dataset we constructed to verify we preserced pair relationships properly\n",
    "for _ in range(8):\n",
    "    print(untokenized_ing_ner_pairs[random.randint(0, len(untokenized_ing_ner_pairs))])\n",
    "\n",
    "# deep check\n",
    "for pair in untokenized_ing_ner_pairs:\n",
    "    assert pair['ner'] in pair['ingredient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02623e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f593905807f347c8b6ff860a799cd562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally, we'll tokenize it!\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "tokenized_pairs = untokenized_ing_ner_pairs.map(lambda examples: tokenizer(examples['ingredient']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04af6cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'ingredient', 'input_ids', 'ner', 'token_type_ids'],\n",
       "    num_rows: 62731\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472b855f",
   "metadata": {},
   "source": [
    "For now, concluding data explorations and experiments with the `datasets` processing tooling. Picking this up in another notebook [IngredientsToNer](./IngredientsToNer.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d84f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recipegen",
   "language": "python",
   "name": "recipegen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
